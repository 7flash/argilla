{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import argilla as rg\n",
    "from argilla.client.feedback.dataset.local import FeedbackDataset\n",
    "from datasets import load_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/kursat/argilla/src/argilla/client/client.py:165: UserWarning: No workspace configuration was detected. To work with Argilla datasets, specify a valid workspace name on `rg.init` or set it up through the `rg.set_workspace` function.\n",
      "  warnings.warn(\n",
      "/Users/kursat/argilla/src/argilla/client/client.py:182: UserWarning: You're connecting to Argilla Server 1.14.1 using a different client version (1.17.0-dev).\n",
      "This may lead to potential compatibility issues during your experience.\n",
      "To ensure a seamless and optimized connection, we highly recommend aligning your client version with the server version.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "rg.init(\n",
    "    api_url=\"http://localhost:6900\",\n",
    "    api_key=\"owner.apikey\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FeedbackDs(FeedbackDataset):\n",
    "    \n",
    "    def __init__(self) -> None:\n",
    "        \"\"\"\n",
    "        task: \n",
    "        \"question_answering\", x \n",
    "        \"text_classification\", x\n",
    "        \"token_classification\", \n",
    "        \"summarization\", x\n",
    "        \"translation\", x \n",
    "\n",
    "        \"supervised-fine-tuning\" x\n",
    "        \"conversational\" x\n",
    "        \"retrieval-augmented-generation\" x\n",
    "        \"sentence-similarity\"\n",
    "        \"\"\"\n",
    "        pass\n",
    "\n",
    "    def add_item(self, items):\n",
    "        \"\"\"\n",
    "        Make sure that the keys of the dictionary are the same as the names of the fields.\n",
    "        :param items: A dictionary containing the fields of the dataset and their values.\n",
    "        :return: None\n",
    "        \"\"\"\n",
    "        dataset_fields = [self.fields[i].name for i in range(len(self.fields))]\n",
    "        record_fields = list(items.keys()) #{'context', 'question'} \n",
    "\n",
    "        if not set(record_fields).issubset(set(dataset_fields)):\n",
    "            raise ValueError(\"Item fields are not subset of dataset fields\")\n",
    "        \n",
    "        text_fields = {}\n",
    "        for indx, field_name in enumerate(dataset_fields):\n",
    "            text_fields[field_name] = items[dataset_fields[indx]]\n",
    "\n",
    "        dataset_length = [len(value) for key, value in items.items()][0]\n",
    "\n",
    "        for item in range(dataset_length):\n",
    "            record = rg.FeedbackRecord(\n",
    "                fields = {dataset_fields[index]: text_fields[field][item] for index, field in enumerate(dataset_fields)}\n",
    "            )\n",
    "            self.add_records(record)\n",
    "            \n",
    "    @classmethod\n",
    "    def for_question_answering(cls, answers=False):\n",
    "        \"\"\"\n",
    "        You can use this method to create a basic dataset for question answering tasks.\n",
    "        To add items to your dataset, use the \"add_item\" method.\n",
    "\n",
    "        :param answers: Set this parameter to True if you want to add answers to your dataset\n",
    "        :return: A FeedbackDataset object for question answering containing \"context\", \"question\" and optionally \"answers\" fields\n",
    "        \"\"\"\n",
    "        ds = rg.FeedbackDataset(\n",
    "            fields=[\n",
    "                rg.TextField(name=\"context\"),\n",
    "                rg.TextField(name=\"question\")\n",
    "                ],\n",
    "            questions=[\n",
    "                rg.TextQuestion(name=\"answer\")\n",
    "            ]\n",
    "        )\n",
    "        if answers:\n",
    "            ds.fields.append(\n",
    "                rg.TextField(name=\"answer\")\n",
    "                )\n",
    "   \n",
    "        custom_ds = cls()\n",
    "        for attr, value in vars(ds).items():\n",
    "            setattr(custom_ds, attr, value)\n",
    "        return custom_ds\n",
    "\n",
    "    @classmethod\n",
    "    def for_text_classification(cls, labels, multi_label=False):\n",
    "        \"\"\"\n",
    "        You can use this method to create a basic dataset for text classification tasks.\n",
    "        :param labels: A list of labels for the classification task.\n",
    "        :param multi_label: Set this parameter to True if you want to create a multi-label classification dataset.\n",
    "        :return: A FeedbackDataset object for text classification containing \"text\" and \"label\" fields.\n",
    "        \"\"\"\n",
    "        ds = rg.FeedbackDataset(\n",
    "            fields=[\n",
    "                rg.TextField(name=\"text\"),\n",
    "                ],\n",
    "            questions=[\n",
    "                rg.LabelQuestion(\n",
    "                name=\"label\",\n",
    "                labels=labels\n",
    "                )\n",
    "            ]\n",
    "        )\n",
    "        if multi_label:\n",
    "            ds = rg.FeedbackDataset(\n",
    "            fields=[\n",
    "                rg.TextField(name=\"text\"),\n",
    "                ],\n",
    "            questions=[\n",
    "                rg.MultiLabelQuestion(\n",
    "                name=\"label\",\n",
    "                labels=labels\n",
    "                )\n",
    "            ]\n",
    "        )\n",
    "\n",
    "        custom_ds = cls()\n",
    "        for attr, value in vars(ds).items():\n",
    "            setattr(custom_ds, attr, value)\n",
    "        return custom_ds\n",
    "    \n",
    "    @classmethod\n",
    "    def for_summarization(cls, labels=False, examples=False):\n",
    "        \"\"\"\n",
    "        You can use this method to create a basic dataset for summarization tasks.\n",
    "        :param: labels: Set this parameter to True if you want to add labels to have the summaries annotated.\n",
    "        :param: examples: Set this parameter to True if you want to add examples for text.\n",
    "        :return: A FeedbackDataset object for summarization containing \"text\" and \"summary\" fields.\n",
    "        \"\"\"\n",
    "        ds = rg.FeedbackDataset(\n",
    "            fields=[\n",
    "                rg.TextField(name=\"text\"),\n",
    "                ],\n",
    "            questions=[\n",
    "                rg.TextQuestion(\n",
    "                name=\"summary\",\n",
    "\n",
    "                )\n",
    "            ]\n",
    "        )\n",
    "        if labels:\n",
    "            ds.questions.append(\n",
    "                rg.LabelQuestion(\n",
    "                name=\"label\",\n",
    "                labels=labels\n",
    "                )\n",
    "            )\n",
    "        if examples:\n",
    "            ds.fields.append(\n",
    "                rg.TextField(name=\"example\")\n",
    "            )\n",
    "\n",
    "        custom_ds = cls()\n",
    "        for attr, value in vars(ds).items():\n",
    "            setattr(custom_ds, attr, value)\n",
    "        return custom_ds\n",
    "    \n",
    "    @classmethod\n",
    "    def for_translation(cls, labels=False, examples=False):\n",
    "        \"\"\"\n",
    "        You can use this method to create a basic dataset for translation tasks.\n",
    "        :param: labels: Set this parameter to True if you want to add labels to have the translations annotated.\n",
    "        :return: A FeedbackDataset object for translation containing \"text\" and \"translation\" fields.\n",
    "        \"\"\"\n",
    "        questions = [rg.TextQuestion(name=\"translation\")]\n",
    "\n",
    "        if labels:\n",
    "            questions.append(rg.LabelQuestion(name=\"label\",labels=labels))\n",
    "\n",
    "        ds = FeedbackDataset(\n",
    "            fields=[\n",
    "                rg.TextField(name=\"text\"),\n",
    "                ],\n",
    "            questions= questions\n",
    "        )\n",
    "\n",
    "        if examples:\n",
    "            ds.fields.append(\n",
    "                rg.TextField(name=\"example\",title=\"Example Translation\")\n",
    "            )\n",
    "\n",
    "        custom_ds = cls()\n",
    "        for attr, value in vars(ds).items():\n",
    "            setattr(custom_ds, attr, value)\n",
    "        return custom_ds\n",
    "    \n",
    "    @classmethod\n",
    "    def for_supervised_fine_tuning(cls, field_names: list):\n",
    "        \"\"\"\n",
    "        \"\"\"\n",
    "        if type(field_names) != list:\n",
    "            field_names = [field_names]\n",
    "\n",
    "        ds = rg.FeedbackDataset(\n",
    "            fields=[\n",
    "                rg.TextField(name=field) for field in field_names\n",
    "                ],\n",
    "            questions=[\n",
    "                rg.TextQuestion(name=\"answer\")\n",
    "            ]\n",
    "        )\n",
    "   \n",
    "        custom_ds = cls()\n",
    "        for attr, value in vars(ds).items():\n",
    "            setattr(custom_ds, attr, value)\n",
    "        return custom_ds\n",
    "    \n",
    "    @classmethod\n",
    "    def for_conversational(cls, system_prompt=False):\n",
    "        \"\"\"\n",
    "        \"\"\"\n",
    "        ds = rg.FeedbackDataset(\n",
    "            fields=[\n",
    "                rg.TextField(name=\"user_prompt\"),\n",
    "                rg.TextField(name=\"response\")\n",
    "                ],\n",
    "            questions=[\n",
    "                rg.TextQuestion(name=\"answer\")\n",
    "            ]\n",
    "        )\n",
    "        if system_prompt:\n",
    "            ds.fields.insert(0,\n",
    "                rg.TextField(name=\"system_prompt\")\n",
    "            )\n",
    "   \n",
    "        custom_ds = cls()\n",
    "        for attr, value in vars(ds).items():\n",
    "            setattr(custom_ds, attr, value)\n",
    "        return custom_ds\n",
    "\n",
    "    @classmethod\n",
    "    def for_rag(cls, retrieval_source=False):\n",
    "        \"\"\"\n",
    "        \"\"\"\n",
    "        ds = rg.FeedbackDataset(\n",
    "            fields=[\n",
    "                rg.TextField(name=\"query\"),\n",
    "                rg.TextField(name=\"retrieved_document\",\n",
    "                             title=\"Retrieved Document\")\n",
    "                ],\n",
    "            questions=[\n",
    "                rg.TextQuestion(name=\"answer\")\n",
    "            ]\n",
    "        )\n",
    "        if retrieval_source:\n",
    "            ds.fields.append(\n",
    "                rg.TextField(name=\"retrieval_source\",\n",
    "                             title=\"Retrieval Source\")\n",
    "            )\n",
    "   \n",
    "        custom_ds = cls()\n",
    "        for attr, value in vars(ds).items():\n",
    "            setattr(custom_ds, attr, value)\n",
    "        return custom_ds\n",
    "    \n",
    "    @classmethod\n",
    "    def for_sentence_similarity(cls):\n",
    "        \"\"\"\n",
    "        \"\"\"\n",
    "        ds = rg.FeedbackDataset(\n",
    "            fields=[\n",
    "                rg.TextField(name=\"premise\"),\n",
    "                rg.TextField(name=\"hypothesis\")\n",
    "                ],\n",
    "            questions=[\n",
    "                rg.LabelQuestion(name=\"relationship\",\n",
    "                                 labels=[\"entailment\", \"neutral\", \"contradiction\"])\n",
    "\n",
    "            ]\n",
    "        )\n",
    "        custom_ds = cls()\n",
    "        for attr, value in vars(ds).items():\n",
    "            setattr(custom_ds, attr, value)\n",
    "        return custom_ds\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "SENTENCE SIMILARITY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_sent_sim = load_dataset(\"plaguss/snli-small\", split=\"train\")\n",
    "dict_sent_sim = {\"premise\": [dataset_sent_sim[\"premise\"][i] for i in range(len(dataset_sent_sim[\"premise\"]))], \"hypothesis\": [dataset_sent_sim[\"hypothesis\"][i] for i in range(len(dataset_sent_sim[\"hypothesis\"]))]}\n",
    "ds_sent_sim = FeedbackDs.for_sentence_similarity()\n",
    "ds_sent_sim.add_item(dict_sent_sim)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "RAG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "dict_rag = {\"query\": [\"What is the status of the war?\"], \"retrieved_document\": [\"The war is over.\"], \"retrieval_source\": [\"wikipedia\"]}\n",
    "ds_rag = FeedbackDs.for_rag(retrieval_source=True)\n",
    "ds_rag.add_item(dict_rag)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "CONVERSATIONAL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "conversational_hf = load_dataset(\"georgesung/OpenOrca_35k\", split=\"train\").shard(index=1, num_shards=1110)\n",
    "dict_conversational_wo_systemprompt = {\"user_prompt\": [conversational_hf[\"question\"][i] for i in range(len(conversational_hf[\"question\"]))], \"response\": [conversational_hf[\"response\"][i] for i in range(len(conversational_hf[\"response\"]))]}\n",
    "dict_conversational_w_systemprompt = {\"user_prompt\": [conversational_hf[\"question\"][i] for i in range(len(conversational_hf[\"question\"]))], \"response\": [conversational_hf[\"response\"][i] for i in range(len(conversational_hf[\"response\"]))], \"system_prompt\": [conversational_hf[\"system_prompt\"][i] for i in range(len(conversational_hf[\"system_prompt\"]))]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_conversational = FeedbackDs.for_conversational(system_prompt=True)\n",
    "ds_conversational.add_item(dict_conversational_w_systemprompt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "SUPERVISED FINETUNING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_supervised = FeedbackDs.for_supervised_fine_tuning([\"instruction\", \"context\", \"response\"])\n",
    "ds_supervised.add_item({\"instruction\": [\"Hello_instruction\"], \"context\": [\"Hello_context\"], \"response\": [\"Hello_response\"]})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "QA "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_items = {\"question\": [\"qq1\"], \"context\": [\"cc1\"]}\n",
    "ds_qa = FeedbackDs.for_question_answering()\n",
    "ds_qa.add_item(data_items)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "SUMMARIZATION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "sum_ds = load_dataset(\"ccdv/govreport-summarization\", split=\"train\").shard(index=0, num_shards=1000)\n",
    "dict_summarization_wo_summary = {\"text\": [sum_ds[\"report\"][i] for i in range(len(sum_ds[\"report\"]))]}\n",
    "dict_summarization_w_summary = {\"text\": [sum_ds[\"report\"][i] for i in range(len(sum_ds[\"report\"]))], \"example\": [sum_ds[\"summary\"][i] for i in range(len(sum_ds[\"summary\"]))]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels_sum = [\"pos\", \"neg\"]\n",
    "ds_summarization = FeedbackDs.for_summarization(labels=labels_sum, examples=False)\n",
    "ds_summarization.add_item(dict_summarization_wo_summary)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TEXTCAT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "textcat_items = {\"text\": [\"I love this movie\", \"I hate this movie\",\"I love it\",\"erwer\"]}\n",
    "labels = [\"pos\", \"neg\"]\n",
    "ds_textcat = FeedbackDs.for_text_classification(labels)\n",
    "ds_textcat.add_item(textcat_items)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TEXTCAT2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/kursat/.cache/huggingface/modules/datasets_modules/datasets/banking77/9898c11f6afa9521953d2ef205667b527bad14ef9cab445d470f16240c8c8ec4/banking77.py:59: FutureWarning: Dataset 'banking77' is deprecated and will be deleted. Use 'PolyAI/banking77' instead.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "ds_banking = load_dataset(\"banking77\", split=\"train\")\n",
    "dict_banking = {\"text\": [ds_banking[\"text\"][i] for i in range(len(ds_banking[\"text\"]))]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = [\"pos\", \"neg\", \"neu\"]\n",
    "ds_textcat2 = FeedbackDs.for_text_classification(labels, multi_label=True)\n",
    "ds_textcat2.add_item(dict_banking)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TRANSLATION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "translation_hf = load_dataset(\"abidlabs/test-translation-dataset\", split=\"train\")\n",
    "dict_translation = {\"text\": [translation_hf[\"Input\"][i] for i in range(len(translation_hf[\"Input\"]))]} #, \"example\": [translation_hf[\"Translation\"][i] for i in range(len(translation_hf[\"Translation\"]))]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_translation = FeedbackDataset.for_translation(labels=False)\n",
    "ds_translation.add_item(dict_translation)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "UPLOAD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Pushing records to Argilla...: 100%|██████████| 2/2 [00:00<00:00, 28.21it/s]\n"
     ]
    }
   ],
   "source": [
    "remote_ds = ds_translation.push_to_argilla(name=\"try37\", workspace=\"admin\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds0 = rg.FeedbackDataset.for_question_answering()\n",
    "ds0.fields[0].use_markdown = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<FeedbackDataset fields=[TextField(name='text', title='Text', required=True, type='text', use_markdown=False)] questions=[TextQuestion(name='translation', title='Translation', description=None, required=True, type='text', use_markdown=False)] guidelines=None>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rg.FeedbackDataset.for_translation()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds0.add_records(rg.FeedbackRecord(fields={\"question\": \"qq1\", \"context\": \"cc1\"}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "for_sentence_similarity\n"
     ]
    }
   ],
   "source": [
    "ds0 = rg.FeedbackDataset.for_sentence_similarity()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "argilla",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.17"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
